{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-29T03:36:44.261132Z",
     "start_time": "2025-04-29T03:36:33.857903Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:37:48.630908Z",
     "start_time": "2025-04-29T03:37:48.583408Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"MPS available: {torch.backends.mps.is_available()}\")",
   "id": "24095869896ccd6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:49:00.713736Z",
     "start_time": "2025-04-29T03:49:00.707733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  Hyperâ€‘parameters\n",
    "MAX_LEN      = 32\n",
    "EMBED_DIM    = 32\n",
    "NUM_FILTERS  = 64\n",
    "KERNEL_SIZES = (3, 4, 5)\n",
    "BATCH_SIZE   = 128\n",
    "EPOCHS       = 15\n",
    "LR           = 3e-4\n",
    "DATA_DIR     = pathlib.Path(\"dataset\")\n",
    "DEVICE       = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ],
   "id": "ec064dd95ebc7bd9",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:49:01.108313Z",
     "start_time": "2025-04-29T03:49:01.105201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#CHECKPOINT\n",
    "@dataclass\n",
    "class Checkpoint:\n",
    "    vocab: dict\n",
    "    state_dict: dict\n",
    "    hyper_params: dict\n",
    "\n",
    "def save_checkpoint(fp: str, model: nn.Module, vocab: dict, **hparams) -> None:\n",
    "    ckpt = Checkpoint(vocab, model.state_dict(), hparams)\n",
    "    torch.save(asdict(ckpt), fp)\n",
    "    print(f\"âœ“ checkpoint saved â†’ {fp}\")\n",
    "\n",
    "def load_checkpoint(fp: str, device: str = \"cpu\"):\n",
    "    data = torch.load(fp, map_location=device)\n",
    "    vocab = data[\"vocab\"]\n",
    "    model = CharCNNClassifier(len(vocab) + 1).to(device)\n",
    "    model.load_state_dict(data[\"state_dict\"])\n",
    "    model.eval()\n",
    "    return model, vocab, data.get(\"hyper_params\", {})"
   ],
   "id": "72200abfac7d752a",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:49:01.165622Z",
     "start_time": "2025-04-29T03:49:01.146512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_lines(path: pathlib.Path) -> List[str]:\n",
    "    with path.open(encoding=\"utf-8\") as f:\n",
    "        return [ln.strip() for ln in f if ln.strip()]\n",
    "\n",
    "# Load raw strings\n",
    "ads      = read_lines(DATA_DIR / \"is_ad_combines_final.txt\")\n",
    "non_ads  = read_lines(DATA_DIR / \"non_ad.txt\")\n",
    "all_strs = ads + non_ads\n",
    "all_lbls = [1] * len(ads) + [0] * len(non_ads)\n",
    "\n",
    "# Build vocabulary (characterâ€‘level, lowerâ€‘cased)\n",
    "chars      = sorted({c.lower() for c in \"\".join(all_strs)})\n",
    "char2idx   = {ch: i + 1 for i, ch in enumerate(chars)}  # 0 = PAD/UNK\n",
    "vocab_size = len(char2idx) + 1\n"
   ],
   "id": "45576aa29692cfc0",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:49:01.180500Z",
     "start_time": "2025-04-29T03:49:01.178586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode(s: str, max_len: int = MAX_LEN) -> torch.Tensor:\n",
    "    idxs = [char2idx.get(c.lower(), 0) for c in s][:max_len]\n",
    "    idxs += [0] * (max_len - len(idxs))\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ],
   "id": "a5c76151ecb8a94a",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:49:01.212737Z",
     "start_time": "2025-04-29T03:49:01.210827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AdDataset(Dataset):\n",
    "    def __init__(self, strings: List[str], labels: List[int]):\n",
    "        self.strings, self.labels = strings, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.strings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return encode(self.strings[idx]), torch.tensor(self.labels[idx], dtype=torch.float32)"
   ],
   "id": "ccd3ebba6b4583b2",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:49:01.252371Z",
     "start_time": "2025-04-29T03:49:01.249517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  Model definition â€“ Character CNN\n",
    "\n",
    "class CharCNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab: int):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab, EMBED_DIM, padding_idx=0)\n",
    "        self.convs = nn.ModuleList(\n",
    "            nn.Conv1d(EMBED_DIM, NUM_FILTERS, k) for k in KERNEL_SIZES\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(NUM_FILTERS * len(KERNEL_SIZES), 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # x: (B, L)\n",
    "        x = self.embed(x).transpose(1, 2)                # (B, E, L)\n",
    "        feats = [torch.relu(conv(x)).max(dim=2).values for conv in self.convs]\n",
    "        x = torch.cat(feats, dim=1)\n",
    "        return self.classifier(x).squeeze(1)             # (B,)"
   ],
   "id": "438a590c455a123d",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:51:18.760294Z",
     "start_time": "2025-04-29T03:51:18.752913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  Training & evaluation helpers\n",
    "\n",
    "def run_epoch(loader: DataLoader, model: nn.Module, criterion, optimizer=None):\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "    total_loss, total_correct, n = 0.0, 0, 0\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            if is_train:\n",
    "                optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            total_loss += loss.item() * y.size(0)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5)\n",
    "            total_correct += (preds == y.bool()).sum().item()\n",
    "            n += y.size(0)\n",
    "    return total_loss / n, total_correct / n\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(DEVICE)\n",
    "            probs = torch.sigmoid(model(x)).cpu()\n",
    "            y_true.extend(y.numpy())\n",
    "            y_pred.extend((probs >= 0.9).long().numpy())\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    acc = (torch.tensor(y_true) == torch.tensor(y_pred)).float().mean().item()\n",
    "    return acc, prec, rec, f1"
   ],
   "id": "ba6e29c3e135f1b6",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:51:32.177667Z",
     "start_time": "2025-04-29T03:51:19.138973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = AdDataset(all_strs, all_lbls)\n",
    "\n",
    "# 70/30 trainâ€‘test split (fixed seed for reproducibility)\n",
    "test_len  = int(len(dataset) * 0.30)\n",
    "train_len = len(dataset) - test_len\n",
    "train_ds, test_ds = random_split(dataset, [train_len, test_len],\n",
    "                                 generator=torch.Generator().manual_seed(42))\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE)\n",
    "\n",
    "model = CharCNNClassifier(vocab_size).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    tr_loss, tr_acc = run_epoch(train_dl, model, criterion, optimizer)\n",
    "    print(f\"epoch {epoch:2d} | train loss {tr_loss:.4f} | train acc {tr_acc:.3f}\")\n",
    "\n",
    "# save final model\n",
    "save_checkpoint(\n",
    "    \"models/model_v5.3.pth\",\n",
    "    model,\n",
    "    vocab=char2idx,\n",
    "    max_len=MAX_LEN,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    num_filters=NUM_FILTERS,\n",
    "    kernel_sizes=KERNEL_SIZES,\n",
    ")\n",
    "\n",
    "# evaluate on heldâ€‘out test set\n",
    "acc, prec, rec, f1 = evaluate(model, test_dl)\n",
    "print(\"\\nðŸ§ª Testâ€‘set metrics\")\n",
    "print(f\"accuracy  : {acc:.3f}\")\n",
    "print(f\"precision : {prec:.3f}\")\n",
    "print(f\"recall    : {rec:.3f}\")\n",
    "print(f\"F1â€‘score  : {f1:.3f}\")"
   ],
   "id": "1858aa9fffe04494",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 | train loss 0.3052 | train acc 0.879\n",
      "epoch  2 | train loss 0.0549 | train acc 0.985\n",
      "epoch  3 | train loss 0.0373 | train acc 0.989\n",
      "epoch  4 | train loss 0.0289 | train acc 0.991\n",
      "epoch  5 | train loss 0.0237 | train acc 0.993\n",
      "epoch  6 | train loss 0.0204 | train acc 0.994\n",
      "epoch  7 | train loss 0.0170 | train acc 0.995\n",
      "epoch  8 | train loss 0.0139 | train acc 0.996\n",
      "epoch  9 | train loss 0.0125 | train acc 0.996\n",
      "epoch 10 | train loss 0.0097 | train acc 0.998\n",
      "epoch 11 | train loss 0.0080 | train acc 0.998\n",
      "epoch 12 | train loss 0.0064 | train acc 0.999\n",
      "epoch 13 | train loss 0.0055 | train acc 0.999\n",
      "epoch 14 | train loss 0.0046 | train acc 0.999\n",
      "epoch 15 | train loss 0.0035 | train acc 0.999\n",
      "âœ“ checkpoint saved â†’ models/model_v5.3.pth\n",
      "\n",
      "ðŸ§ª Testâ€‘set metrics\n",
      "accuracy  : 0.991\n",
      "precision : 0.996\n",
      "recall    : 0.983\n",
      "F1â€‘score  : 0.989\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T03:52:34.326640Z",
     "start_time": "2025-04-29T03:52:34.320932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "We want to maximize precision since we do not want any false positives\n",
    "v5: 0.993\n",
    "v5.1: 0.992\n",
    "v5.2: 0.995\n",
    "v5.3: 0.996 with 0.9 threshold\n",
    "v5.4: 0.997 ^\n",
    "\"\"\""
   ],
   "id": "fce000cec7a890ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe want to maximize precision since we do not want any false positives\\nv5: 0.993\\nv5.1: 0.992\\nv5.2: 0.995\\nv5.3: 0.996 with 0.9 threshold\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9f655b2eb7f07c5a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
